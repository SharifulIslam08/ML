{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:42:01.273573Z",
     "start_time": "2020-06-16T21:42:01.267581Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Initialize the Variables required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:42:01.885578Z",
     "start_time": "2020-06-16T21:42:01.869592Z"
    }
   },
   "outputs": [],
   "source": [
    "X1=tf.Variable(initial_value=[0.,1.,0.,1.])\n",
    "X2=tf.Variable(initial_value=[0.,0.,1.,1.])\n",
    "Y_AND=tf.Variable(initial_value=[0.,0.,0.,1.])\n",
    "Y_NOR=tf.Variable(initial_value=[1.,0.,0.,0.])\n",
    "Y_OR=tf.Variable(initial_value=[0.,1.,1.,1.])\n",
    "Y_XOR=tf.Variable(initial_value=[0.,1.,1.,0.])\n",
    "Y_XNOR=tf.Variable(initial_value=[1.,0.,0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:44:42.718205Z",
     "start_time": "2020-06-16T21:44:42.713210Z"
    }
   },
   "outputs": [],
   "source": [
    "# At First we will find weights for AND,OR and NOR Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:44:59.623799Z",
     "start_time": "2020-06-16T21:44:59.618804Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let us define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:00.293832Z",
     "start_time": "2020-06-16T21:45:00.280846Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    " \n",
    "   def __init__(self):\n",
    "        \n",
    "         # Initialize the weights to `2.0` and the bias to `2.0`\n",
    "         # In practice, these should be initialized to random values\n",
    "         # self.W1=tf.random.normal([1])\n",
    "        self.W1 = tf.Variable(2.)\n",
    "        self.W2= tf.Variable(2.)\n",
    "        self.b=tf.Variable(2.)\n",
    "   \n",
    "   def __call__(self, x1,x2):\n",
    "        self.K1=self.W1 * x1 + self.W2 * x2 + self.b\n",
    "        self.Output = tf.keras.activations.sigmoid(self.K1)\n",
    "        return(self.Output)\n",
    "model=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:14.127469Z",
     "start_time": "2020-06-16T21:45:14.123471Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cost function will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:14.708758Z",
     "start_time": "2020-06-16T21:45:14.701765Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(target_y, predicted_y):\n",
    "    c=tf.keras.losses.BinaryCrossentropy()\n",
    "    return(c(target_y,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:16.146802Z",
     "start_time": "2020-06-16T21:45:16.141809Z"
    }
   },
   "outputs": [],
   "source": [
    "def None_to_Zero(v):\n",
    "    if v==None:\n",
    "        v=0\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:17.574708Z",
     "start_time": "2020-06-16T21:45:17.566714Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, X1, X2, Y2, learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "            current_loss = compute_cost(Y2,model(X1,X2))\n",
    "    dW1,dW2,db=t.gradient(current_loss,[model.W1,model.W2,model.b])          \n",
    "    dW1=None_to_Zero(dW1)\n",
    "    db=None_to_Zero(db)\n",
    "    dW2=None_to_Zero(dW2)\n",
    "    model.W1.assign_sub(learning_rate * dW1)\n",
    "    model.b.assign_sub(learning_rate * db)\n",
    "    model.W2.assign_sub(learning_rate * dW2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:25.216688Z",
     "start_time": "2020-06-16T21:45:20.117436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# As we have very less Input data we need to increase the number of # epochs or the learning rate. \n",
    "epochs=range(1000)\n",
    "learning_rate=0.1\n",
    "for epoch in epochs:\n",
    "    train(model, X1, X2,Y_AND, learning_rate)\n",
    "   # train(model, X1, X2,Y_NOR, learning_rate)\n",
    "   # train(model, X1, X2,Y_OR, learning_rate)\n",
    "#Once the training is done we can find results by calling the Model  #Class object as \n",
    "print(np.round(model(X1, X2).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:25.227676Z",
     "start_time": "2020-06-16T21:45:25.219685Z"
    }
   },
   "outputs": [],
   "source": [
    "W_AND={'W1':model.W1.numpy(),'W2':model.W2.numpy(),'b':model.b.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:25.365341Z",
     "start_time": "2020-06-16T21:45:25.233672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-4.9358997>"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:25.499241Z",
     "start_time": "2020-06-16T21:45:25.370336Z"
    }
   },
   "outputs": [],
   "source": [
    "#W_AND={'W1':3.1480012,'W2':3.1480012,'b':-4.9358997}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:25.629006Z",
     "start_time": "2020-06-16T21:45:25.504235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': 3.1480012, 'W2': 3.1480012, 'b': -4.9358997}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_AND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For OR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:30.908392Z",
     "start_time": "2020-06-16T21:45:25.632004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "epochs=range(1000)\n",
    "learning_rate=0.1\n",
    "for epoch in epochs:\n",
    "    train(model, X1, X2,Y_OR, learning_rate)\n",
    "#Once the training is done we can find results by calling the Model  #Class object as \n",
    "print(np.round(model(X1, X2).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:30.920383Z",
     "start_time": "2020-06-16T21:45:30.911391Z"
    }
   },
   "outputs": [],
   "source": [
    "W_OR={'W1':model.W1.numpy(),'W2':model.W2.numpy(),'b':model.b.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:31.064686Z",
     "start_time": "2020-06-16T21:45:30.925377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': 5.6196923, 'W2': 5.6196923, 'b': -2.3270602}"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For NOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:36.362143Z",
     "start_time": "2020-06-16T21:45:31.073674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "epochs=range(1000)\n",
    "learning_rate=0.1\n",
    "for epoch in epochs:\n",
    "    train(model, X1, X2,Y_NOR, learning_rate)\n",
    "#Once the training is done we can find results by calling the Model  #Class object as \n",
    "print(np.round(model(X1, X2).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:36.372133Z",
     "start_time": "2020-06-16T21:45:36.365141Z"
    }
   },
   "outputs": [],
   "source": [
    "W_NOR={'W1':model.W1.numpy(),'W2':model.W2.numpy(),'b':model.b.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:36.509225Z",
     "start_time": "2020-06-16T21:45:36.375131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94292766"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:36.628393Z",
     "start_time": "2020-06-16T21:45:36.513221Z"
    }
   },
   "outputs": [],
   "source": [
    "# W_NOR={'W1':-3.0863311,'W2':-3.0863311,'b':0.94292766}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:45:36.821691Z",
     "start_time": "2020-06-16T21:45:36.630573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': -3.0863311, 'W2': -3.0863311, 'b': 0.94292766}"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_NOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:46:02.986286Z",
     "start_time": "2020-06-16T21:46:02.959313Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model_XOR(object):\n",
    "    \n",
    " \n",
    "    def __init__(self):\n",
    "        self.W11 = tf.Variable(W_AND['W1'])\n",
    "        self.W12= tf.Variable(W_AND['W2'])\n",
    "        self.b13=tf.Variable(W_AND['b'])\n",
    "        self.W14 = tf.Variable(W_NOR['W1'])\n",
    "        self.W15= tf.Variable(W_NOR['W2'])\n",
    "        self.b16=tf.Variable(W_NOR['b'])\n",
    "        self.W21 = tf.Variable(W_NOR['W1'])\n",
    "        self.W22= tf.Variable(W_NOR['W2'])\n",
    "        self.b23=tf.Variable(W_NOR['b'])\n",
    "\n",
    "    def __call__(self, x1,x2):\n",
    "        self.W1=self.W11 * x1 + self.W12*x2 + self.b13\n",
    "        self.W2=self.W14 * x1 + self.W15*x2 + self.b16\n",
    "        self.A1 = tf.keras.activations.sigmoid(self.W1)\n",
    "        self.A2 = tf.keras.activations.sigmoid(self.W2)\n",
    "        self.W3=self.W21 * self.A1 + self.W22*self.A2 + self.b23\n",
    "        self.A3 = tf.keras.activations.sigmoid(self.W3)\n",
    "        return(self.A3)\n",
    "model_xor=Model_XOR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:46:04.096036Z",
     "start_time": "2020-06-16T21:46:04.087047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-3.0863311>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xor.W14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:46:06.596834Z",
     "start_time": "2020-06-16T21:46:06.577851Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_xor(model_xor, X1, X2, Y2, learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = compute_cost(Y2,model_xor(X1,X2))\n",
    "            \n",
    " \n",
    "    dW11,dW12,db13,dW14,dW15,db16,dW21,dW22,db23=t.gradient(current_loss,[model_xor.W11,model_xor.W12,model_xor.b13,\n",
    "                                                                            model_xor.W14,model_xor.W15,model_xor.b16,\n",
    "                                                                            model_xor.W21,model_xor.W22,model_xor.b23,])\n",
    "    \n",
    " \n",
    "    model_xor.W11.assign_sub(learning_rate * None_to_Zero(dW11))\n",
    "    model_xor.b13.assign_sub(learning_rate * None_to_Zero(db13))\n",
    "    model_xor.W12.assign_sub(learning_rate * None_to_Zero(dW12))\n",
    "    model_xor.W14.assign_sub(learning_rate * None_to_Zero(dW14))\n",
    "    model_xor.b16.assign_sub(learning_rate * None_to_Zero(db16))\n",
    "    model_xor.W15.assign_sub(learning_rate * None_to_Zero(dW15))\n",
    "    model_xor.W21.assign_sub(learning_rate * None_to_Zero(dW21))\n",
    "    model_xor.b23.assign_sub(learning_rate * None_to_Zero(db23))\n",
    "    model_xor.W22.assign_sub(learning_rate * None_to_Zero(dW22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:46:09.612525Z",
     "start_time": "2020-06-16T21:46:08.757322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "epochs=range(100)\n",
    "learning_rate=0.1\n",
    "for epoch in epochs:\n",
    "    train_xor(model_xor, X1, X2,Y_XOR, learning_rate)\n",
    "   #Once the training is done we can find results by calling the Model_XOR  #Class object as \n",
    "print(np.round(model_xor(X1, X2).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:46:16.005067Z",
     "start_time": "2020-06-16T21:46:15.994076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.27440244, 0.6892559 , 0.6892559 , 0.2543708 ], dtype=float32)>"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xor(X1, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for XNOR Gate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:46:56.603628Z",
     "start_time": "2020-06-16T21:46:56.582648Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model_XNOR(object):\n",
    "    \n",
    " \n",
    "    def __init__(self):\n",
    "        self.W11 = tf.Variable(W_AND['W1'])\n",
    "        self.W12= tf.Variable(W_AND['W2'])\n",
    "        self.b13=tf.Variable(W_AND['b'])\n",
    "        self.W14 = tf.Variable(W_NOR['W1'])\n",
    "        self.W15= tf.Variable(W_NOR['W2'])\n",
    "        self.b16=tf.Variable(W_NOR['b'])\n",
    "        self.W21 = tf.Variable(W_OR['W1'])\n",
    "        self.W22= tf.Variable(W_OR['W2'])\n",
    "        self.b23=tf.Variable(W_OR['b'])\n",
    "\n",
    "    def __call__(self, x1,x2):\n",
    "        self.W1=self.W11 * x1 + self.W12*x2 + self.b13\n",
    "        self.W2=self.W14 * x1 + self.W15*x2 + self.b16\n",
    "        self.A1 = tf.keras.activations.sigmoid(self.W1)\n",
    "        self.A2 = tf.keras.activations.sigmoid(self.W2)\n",
    "        self.W3=self.W21 * self.A1 + self.W22*self.A2 + self.b23\n",
    "        self.A3 = tf.keras.activations.sigmoid(self.W3)\n",
    "        return(self.A3)\n",
    "model_xnor=Model_XNOR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:46:58.920368Z",
     "start_time": "2020-06-16T21:46:58.908376Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_xnor(model_xnor, X1, X2, Y2, learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = compute_cost(Y2,model_xnor(X1,X2))\n",
    "            \n",
    " \n",
    "    dW11,dW12,db13,dW14,dW15,db16,dW21,dW22,db23=t.gradient(current_loss,[model_xnor.W11,model_xnor.W12,model_xnor.b13,\n",
    "                                                                            model_xnor.W14,model_xnor.W15,model_xnor.b16,\n",
    "                                                                            model_xnor.W21,model_xnor.W22,model_xnor.b23,])\n",
    "    \n",
    " \n",
    "    model_xnor.W11.assign_sub(learning_rate * None_to_Zero(dW11))\n",
    "    model_xnor.b13.assign_sub(learning_rate * None_to_Zero(db13))\n",
    "    model_xnor.W12.assign_sub(learning_rate * None_to_Zero(dW12))\n",
    "    model_xnor.W14.assign_sub(learning_rate * None_to_Zero(dW14))\n",
    "    model_xnor.b16.assign_sub(learning_rate * None_to_Zero(db16))\n",
    "    model_xnor.W15.assign_sub(learning_rate * None_to_Zero(dW15))\n",
    "    model_xnor.W21.assign_sub(learning_rate * None_to_Zero(dW21))\n",
    "    model_xnor.b23.assign_sub(learning_rate * None_to_Zero(db23))\n",
    "    model_xnor.W22.assign_sub(learning_rate * None_to_Zero(dW22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:47:01.214183Z",
     "start_time": "2020-06-16T21:47:00.401937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "epochs=range(100)\n",
    "learning_rate=0.1\n",
    "for epoch in epochs:\n",
    "    train_xnor(model_xnor, X1, X2,Y_XNOR, learning_rate)\n",
    "   #Once the training is done we can find results by calling the Model_XOR  #Class object as \n",
    "print(np.round(model_xnor(X1, X2).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
